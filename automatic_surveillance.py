# -*- coding: utf-8 -*-
"""automatic-surveillance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OkuSMydY7hvKMvp1fVJcMSFlvILFOgem

# Automatic Surveillance
Marco Schivo - marcoschivo@live.it


Ammar Darwesh - ammardarwesh33@gmail.com
"""

!pip install roboflow
from roboflow import Roboflow

# another good usable dataset
# project = rf.workspace("smart-weapon-system-with-computer-vision").project("drdo")

rf = Roboflow(api_key="N21J841SQZnqYv7zcs2a")
project = rf.workspace("nader-uvd2t").project("nader")
version = project.version(1)
dataset = version.download("yolov8")

"""# Troubleshooting

Modify the last line of data.yaml with (or something similar):

```
path: /content/DRDO-1  # path of the dataset
test: test/images      # relatives paths to the above...
train: train/images
val: valid/images
```

*   different pretrained model can be used: X = n/s/m/l/c for yolov8(X).pt
*   .pt stands for pytorch

# Mount google drive folder
"""

from google.colab import drive
drive_path = '/content/drive'
drive.mount(drive_path)

!pip install ultralytics

from ultralytics import YOLO
import os

trained_model = '/content/drive/MyDrive/Colab Notebooks/project_ml/train4/weights/best.pt'

if not os.path.exists(trained_model):
  print('uploading COCO pre-trained model')
  model = YOLO('yolov8n.pt')
else:
  print('uploading partially trained model')
  model = YOLO(trained_model)

"""# Train the uploaded model"""

results = model.train(data=dataset.location + '/data.yaml', epochs=100)

"""# Inferencing"""

from ultralytics import YOLO

# Load a pretrained YOLOv8n model
# model = YOLO('/content/runs/detect/train8/weights/best.pt')

# Define path to the image file
source = '/content/drive/MyDrive/Colab Notebooks/project_ml/video2.mp4'

# Run inference on the source
# results = model(source)  # list of Results objects

results = model.predict(source, stream=True, save=True, conf=0.6)

# output_folder = '/content/out_imgs'

i = 0
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen
    # result.save(filename=output_folder + '/' + str(i) + '.jpg')  # save to disk
    i = i + 1